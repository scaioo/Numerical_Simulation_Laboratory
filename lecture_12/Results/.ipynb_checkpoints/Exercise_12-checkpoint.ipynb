{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Numerical Simulation Laboratory </span>\n",
    "## <span style=\"color:brown\"> Python Exercise 12 </span>\n",
    "## <span style=\"color:orange\"> Keras - Deep & Convolutional Neural Network image recognition </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.1\n",
    "\n",
    "<span style=\"color:red\">Change at will and train your DNN by increasing the number of epochs to an adeuqate value</span>. Try to use at least two other optimizers, different from SGD: <span style=\"color:red\">watch to accuracy and loss for training and validation data and comment on the performances</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 14:23:20.228723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-25 14:23:20.469431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-25 14:23:20.545570: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-25 14:23:21.203206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-25 14:24:14.691802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.random.set_seed(seed)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "# output\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "# reshape data, it could depend on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "# cast to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# convert class vectors to binary class matrices, e.g. for use with categorical_crossentropy\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compile_model():\n",
    "    # create the model\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adadelta(),metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "# create the deep neural net\n",
    "model_DNN = compile_model()\n",
    "# train DNN and store training info in history\n",
    "history = model_DNN.fit(X_train, Y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, Y_test))\n",
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "#X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "predictions = model_DNN.predict(X_test)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols,1)\n",
    "\n",
    "plt.figure(figsize=(15, 15)) \n",
    "for i in range(10):    \n",
    "    ax = plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(X_test[i, :, :, 0], cmap='gray')    \n",
    "    plt.title(\"Digit: {}\\nPredicted:    {}\".format(np.argmax(Y_test[i]), np.argmax(predictions[i])))    \n",
    "    plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Convolutional Neural Nets with Keras\n",
    "\n",
    "We have so far considered each MNIST data sample as a $(28\\times 28,)$-long 1d vector. On the other hand, we do know that in every one of the hand-written digits there are *local* spatial correlations between the pixels, but also *translational invariance*, which we would like to take advantage of to improve the accuracy of our classification model. To this end, we first need to reshape the training and test input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# you will need the following for Convolutional Neural Networks\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can ask the question of whether a neural net can learn to recognize such local patterns. This can be achieved by using convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.2\n",
    "\n",
    "Change the architecture of your DNN using convolutional layers. Use `Conv2D`, `MaxPooling2D`, `Dropout`, but also do not forget `Flatten`, a standard `Dense` layer and `soft-max` in the end. I have merged step 2 and 3 in the following definition of `create_CNN()` that **<span style=\"color:red\">you should complete</span>**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS INCOMPLETE ... COMPLETE BEFORE EXECUTING IT\n",
    "\n",
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    #\n",
    "    # ADD HERE SOME OTHER LAYERS AT YOUR WILL, FOR EXAMPLE SOME: Dropout, 2D pooling, 2D convolutional etc. ... \n",
    "    # remember to move towards a standard flat layer in the final part of your DNN,\n",
    "    # and that we need a soft-max layer with num_classes=10 possible outputs\n",
    "    #\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='SGD',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your DCNN and evaluate its performance proceeding exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "batch_size = 32\n",
    "epochs = # INSERT HERE AN ADEQUATE NUMBER OF EPOCHS!\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, **<span style=\"color:red\">add the evaluation of your CNN performances</span>** like that used for the DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12.3\n",
    "\n",
    "Use the `gimp` application to create 10 pictures of your \"handwritten\" digits, import them in your jupyter-notebook and try to see if your CNN is able to recognize your handwritten digits.\n",
    "\n",
    "For example, you can use the following code to import a picture of an handwritten digit\n",
    "(Note: you should install Python Image Library (PIL/Pillow):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO LOAD FILES ON GOOGLE COLAB\n",
    "#from google.colab import files\n",
    "#upload = files.upload() #this will let you browse and choose the file to be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 28x28\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "digit_filename = \"./Pictures/8b.png\"\n",
    "digit_in = Image.open(digit_filename).convert('L')\n",
    "#digit_in = Image.open(\"8b.png\").convert('L') #ON GOOGLE COLAB INSERT THE NAME OF THE UPLOADED FILE\n",
    "\n",
    "ydim, xdim = digit_in.size\n",
    "print(\"Image size: \"+str(xdim)+\"x\"+str(ydim))\n",
    "pix=digit_in.load();\n",
    "data = np.zeros((xdim, ydim))\n",
    "for j in range(ydim):\n",
    "    for i in range(xdim):\n",
    "        data[i,j]=pix[j,i]\n",
    "\n",
    "data /= 255\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(data, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the previously trained DNN to predict the digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(1, 784)\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data = data.reshape(1,xdim*ydim)\n",
    "print(data.shape)\n",
    "pred_0 = model_DNN.predict(data)\n",
    "\n",
    "data = data.reshape(xdim,ydim)\n",
    "\n",
    "plt.figure(figsize=(5, 5))  \n",
    "plt.imshow(data, cmap='gray')    \n",
    "plt.title(\"Digit predicted:    {}\".format(np.argmax(pred_0)))\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Supplementary information 1: Use of `gimp` </span>\n",
    "\n",
    "- from the Unix shell type: `gimp` and hit `Return`\n",
    "- File -> new (chose: 28x28 pixels)\n",
    "- rascale the image to 800%\n",
    "- Use the **brush** with dimension 2px to draw your digit\n",
    "- Color -> invert (to have black background)\n",
    "- Export the image as a `.png` file\n",
    "\n",
    "That's all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Supplementary information 2: Display trained filters in your CNN</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print your NN layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_index=0\n",
    "for layer in model_CNN.layers:\n",
    "    print(layer_index, layer.name)\n",
    "    layer_index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display your filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_index should be the index of a convolutional layer\n",
    "layer_index=0\n",
    "# retrieve weights from the convolutional hidden layer\n",
    "filters, biases = model_CNN.layers[layer_index].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "print(filters.shape)\n",
    "\n",
    "# plot filters\n",
    "n_filters, ix = filters.shape[3], 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # specify subplot and turn of axis\n",
    "    ax = plt.subplot(1,n_filters, ix)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # plot filter channel in grayscale\n",
    "    plt.imshow(f[:, :, 0], cmap='gray')\n",
    "    ix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">Supplementary information 3: Monitor layer outputs in your CNN</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_index = 0\n",
    "\n",
    "from keras.models import Model\n",
    "layer_outputs = [layer.output for layer in model_CNN.layers]\n",
    "activation_model = Model(inputs=model_CNN.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(X_test[test_index].reshape(1,28,28,1))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, layer_index): \n",
    "    activation = activations[layer_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*3,col_size*3))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
    "            activation_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.imshow(X_test[test_index][:,:,0], cmap='gray')\n",
    "# def display_activation(activations, col_size, row_size, layer number)\n",
    "display_activation(activations, 4, 2, 0)\n",
    "# col_size x row_size must be <= Number of filters for the convolutional layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
